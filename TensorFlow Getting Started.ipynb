{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with TensorFlow\n",
    "\n",
    " <span style=\"font-size:0.8em\">Based on [Getting Started with Tensor Flow](https://www.tensorflow.org/get_started/get_started).</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your tensorflow and python versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 1.2.0\n",
      "python version is: 3.5.3 |Continuum Analytics, Inc.| (default, May 15 2017, 10:43:23) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow version:\",tf.__version__)\n",
    "print(\"python version is:\", sy.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a TensorFlow Computation Graph\n",
    "<p>In a tensorflow program, you are required to build a computational graph. You build the graph \n",
    "by adding *nodes* to the graph. Nothing is actually computed until you execute the operations in the graph. The graph is run\n",
    "in a tensorflow [session](https://www.tensorflow.org/api_docs/python/tf/Session). <code>tf.Session</code> is a class for running (or executing) tensorflow graph operations. </p>\n",
    "<p>\n",
    "Let's begin with *Hello World* in tensorflow\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello World')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the *Hello World* program the tf.constant hello is a *node*. By running the node in a *Session* we perform the operations specified in the node. It can seem unusual to run a constant, but this is how all operations work in tensorflow. Watch what happens if we attempt to evaluate the tf.constant directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.constant named <code>hello</code> is a tensor of type string. The value cannot be evaluated outside a session. <br>\n",
    "Consider basic math operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "nodeA = 7\n",
    "nodeB = 3\n",
    "nodeC = tf.add(nodeA,nodeB)\n",
    "print(sess.run(nodeC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than constants, consider the use of parameters in a graph. This is accomplished by using a tensorflow **placeholder**. Consider the following [tf.placeholder](https://www.tensorflow.org/get_started/get_started) examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.placeholder(tf.float32)\n",
    "node2 = tf.placeholder(tf.float32)\n",
    "nodeAdd = tf.add(node1,node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values are provided to a palceholder by using a <code>feed_dict</code> for feed dictionary. Since placeholders are nodes the must be fed a value and evalued in a tensorflow session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.85958\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(nodeAdd,feed_dict ={node1:2.718, node2:3.14158} ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to placeholders, which must be fed input data inside a session, there are also tensorflow **Variables** called [tf.Variable](https://www.tensorflow.org/api_docs/python/tf/Variable). They can take on different values and they  maintain state in the tensorflow graph across calls to run() of the tensorflow session.Note the following example of a very simple neural network like computation that uses both <code>tf.Variable</code> and <code>tf.placeholder</code>\n",
    "\n",
    "### Simple Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model =  x * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above we have a <code>tf.Variable</code> tensor (a node) for the weights in a neural network called <code>W</code>, a tf.Variable for the bias <code>b</code>, and tf.placeholder for the inputs. The tensor <code>linear_model</code> is the output. Before we execute these operatins in a tensorflow graph, the tf.Variable items must be initialized. This initialialization must tae place in a tensorflow session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate <code>linear_model</code> in a session. The placeholder is used to accept input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model, feed_dict={x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to sum the product or the weights and the inputs as we do in a **neural netwok**. In this case we would use [tf.reduce_sum](https://www.tensorflow.org/api_docs/python/tf/reduce_sum). <code>tf.reduce_sum</code> is used to sum the elements across a tensor.  Consider the following modification. In this case we sum the products of the weights and the inputs and then add the bias. This is a  simple implementation of a single neuron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.70000005]\n"
     ]
    }
   ],
   "source": [
    "linear_model2 = tf.reduce_sum(x*W) + b\n",
    "print(sess.run(linear_model2, feed_dict={x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loss (Error )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Continuing with the original example (<code>linear_model</code>), suppose wanted to evaluate the accuracy of our model. A loss (or error) function compares the model output with the expected output. Since error can be positive or negative, it is a common practice to square the error. This ensures that the error is positive and also penalizes large errors more than small errors. to compute the error of our model, we will provide a <code>tf.placeholder for the truth data. We will also square and sum the errors (often referred to as the *sum of squared errors*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error (loss) is: 23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_errors = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_errors)\n",
    "print(\"The error (loss) is:\", sess.run(loss, feed_dict = {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "The error is high because of the values of W and b. In machine learning, the model is trained, with data, to minimize the error. When the model is trained, the weights are adjusted to minimize the error.  One of the most widely used techniques to minimize error is ***gradient descent***. There are many resources for learning gradient descent. [Here](https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/) is a recommended reference. \n",
    "</p>\n",
    "<p>\n",
    "Tensorflow provides tools to train the model. These tools are provided in the [tf.train](https://www.tensorflow.org/api_docs/python/tf/train) API. This API provides an easy way to train networks using gradient descent.  The [<code>tf.train.GradientDescentOptimizer</code>](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer) class implements the gradient descent algorithm. The <code>minimize</code> method of this class provides a way to compute and apply (descent) a gradient. We pass a learning rate parameter which govern the size of the gradient descent steps. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the optimize step 1000 times, in a tensorflow session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_steps = 1000\n",
    "sess.run(init) \n",
    "for i in range(training_steps): \n",
    "    sess.run(train, feed_dict = {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, the weights should be adusted to minimimze the error. Lets check the loss: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error (loss) is: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_errors = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_errors)\n",
    "print(\"The error (loss) is:\", sess.run(loss, feed_dict = {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check the weights and the bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, the weight is: [-0.9999969]\n",
      "and the bias is [ 0.99999082]\n"
     ]
    }
   ],
   "source": [
    "print(\"After training, the weight is:\", sess.run(W))\n",
    "print(\"and the bias is\", sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we go back to the original weights and biases, note the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error (loss) is: 23.66\n"
     ]
    }
   ],
   "source": [
    "sess.run(init) \n",
    "y = tf.placeholder(tf.float32)\n",
    "squared_errors = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_errors)\n",
    "print(\"The error (loss) is:\", sess.run(loss, feed_dict = {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To double check, watch what happens if we hard set the weights and the bias, to trained weight and bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-0.9999969])\n",
    "fixb = tf.assign(b, [0.99999082])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this exercise we performed the following: \n",
    "- built a linear regression model using tf.Variable and tf.placeholder \n",
    "- briefly looked at how a similar approach could be used to build a simple neural network \n",
    "- calculated the error in our simple network\n",
    "- use the <code>tf.train</code> API to train our network using **gradient descent**\n",
    "- evaluated the error after tarining the network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
